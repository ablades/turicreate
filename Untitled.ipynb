{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change if applicable\n",
    "ig02_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images in random order\n",
    "raw_sf = tc.image_analysis.load_images(ig02_path, recursive=True,\n",
    "                                       random_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split file names so that we can determine what kind of image each row is\n",
    "# E.g. bike_005.mask.0.png -> ['bike_005', 'mask']\n",
    "info = raw_sf['path'].apply(lambda path: os.path.basename(path).split('.')[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to 'name' and 'type'\n",
    "info = info.unpack().rename({'X.0': 'name', 'X.1': 'type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to our main SFrame\n",
    "raw_sf = raw_sf.add_columns(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract label (e.g. 'bike') from name (e.g. 'bike_003')\n",
    "raw_sf['label'] = raw_sf['name'].apply(lambda name: name.split('_')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original path no longer needed\n",
    "del raw_sf['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into images and masks\n",
    "sf_images = raw_sf[raw_sf['type'] == 'image']\n",
    "sf_masks = raw_sf[raw_sf['type'] == 'mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_bbox_coordinates(img):\n",
    "    \"\"\"\n",
    "    Takes a tc.Image of a mask and returns a dictionary representing bounding\n",
    "    box coordinates: e.g. {'x': 100, 'y': 120, 'width': 80, 'height': 120}\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    mask = img.pixel_data\n",
    "    if mask.max() == 0:\n",
    "        return None\n",
    "    # Take max along both x and y axis, and find first and last non-zero value\n",
    "    x0, x1 = np.where(mask.max(0))[0][[0, -1]]\n",
    "    y0, y1 = np.where(mask.max(1))[0][[0, -1]]\n",
    "\n",
    "    return {'x': (x0 + x1) / 2, 'width': (x1 - x0),\n",
    "            'y': (y0 + y1) / 2, 'height': (y1 - y0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert masks to bounding boxes (drop masks that did not contain bounding box)\n",
    "sf_masks['coordinates'] = sf_masks['image'].apply(mask_to_bbox_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There can be empty masks (which returns None), so let's get rid of those\n",
    "sf_masks = sf_masks.dropna('coordinates')\n",
    "\n",
    "# Combine label and coordinates into a bounding box dictionary\n",
    "sf_masks = sf_masks.pack_columns(['label', 'coordinates'],\n",
    "                                 new_column_name='bbox', dtype=dict)\n",
    "\n",
    "# Combine bounding boxes of the same 'name' into lists\n",
    "sf_annotations = sf_masks.groupby('name',\n",
    "                                 {'annotations': tc.aggregate.CONCAT('bbox')})\n",
    "\n",
    "# Join annotations with the images. Note, some images do not have annotations,\n",
    "# but we still want to keep them in the dataset. This is why it is important to\n",
    "# a LEFT join.\n",
    "sf = sf_images.join(sf_annotations, on='name', how='left')\n",
    "\n",
    "# The LEFT join fills missing matches with None, so we replace these with empty\n",
    "# lists instead using fillna.\n",
    "sf['annotations'] = sf['annotations'].fillna([])\n",
    "\n",
    "# Remove unnecessary columns\n",
    "del sf['type']\n",
    "\n",
    "# Save SFrame\n",
    "sf.save('ig02.sframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data =  tc.SFrame('ig02.sframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a train-test split\n",
    "train_data, test_data = data.random_split(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'image' as feature column\n",
      "Using 'annotations' as annotations column\n",
      "Downloading https://docs-assets.developer.apple.com/turicreate/models/darknet.params\n",
      "Download completed: /var/folders/w5/s_vr9kr52sx9s8018zwk0cjnhq5bg1/T/model_cache/darknet.params\n",
      "Setting 'batch_size' to 12\n",
      "Using CPU to create model\n",
      "NOTE: If available, an AMD GPU can be leveraged on macOS 10.14+ for faster model creation\n",
      "+--------------+--------------+--------------+\n",
      "| Iteration    | Loss         | Elapsed Time |\n",
      "+--------------+--------------+--------------+\n",
      "| 1            | 6.086        | 11.5         |\n",
      "| 2            | 6.045        | 16.4         |\n",
      "| 3            | 6.281        | 21.2         |\n",
      "| 4            | 6.233        | 26.2         |\n",
      "| 5            | 6.248        | 31.8         |\n",
      "| 6            | 6.214        | 36.8         |\n",
      "| 7            | 6.174        | 42.0         |\n",
      "| 8            | 6.133        | 46.9         |\n",
      "| 9            | 6.126        | 51.7         |\n",
      "| 10           | 6.251        | 56.5         |\n",
      "+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.stdout = open('test.txt', 'w')\n",
    "# Create a model\n",
    "model = tc.object_detector.create(train_data, batch_size= 12, max_iterations= 10, verbose=True, all_iterations=True)\n",
    "#sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'image' as feature column\n",
      "Using 'annotations' as annotations column\n",
      "Setting 'batch_size' to 12\n",
      "Using CPU to create model\n",
      "NOTE: If available, an AMD GPU can be leveraged on macOS 10.14+ for faster model creation\n",
      "+--------------+--------------+--------------+\n",
      "| Iteration    | Loss         | Elapsed Time |\n",
      "+--------------+--------------+--------------+\n",
      "| 1            | 5.673        | 3.4          |\n",
      "| 4            | 5.835        | 15.0         |\n",
      "| 7            | 6.023        | 26.4         |\n",
      "| 10           | 6.075        | 37.8         |\n",
      "+--------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.stdout = open('test.txt', 'w')\n",
    "# Create a model\n",
    "model1 = tc.object_detector.create(train_data, batch_size= 12, max_iterations= 10, verbose=True, all_iterations=False)\n",
    "#sys.stdout.close()\n",
    "#all iterations turned off prints occasionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.stdout = open('test.txt', 'w')\n",
    "# Create a model\n",
    "model = tc.object_detector.create(train_data, batch_size= 12, max_iterations= 20, verbose=True, all_iterations=True)\n",
    "#sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.stdout = open('test.txt', 'w')\n",
    "# Create a model\n",
    "model1 = tc.object_detector.create(train_data, batch_size= 12, max_iterations= 20, verbose=True, all_iterations=False)\n",
    "#sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.stdout = open('test.txt', 'w')\n",
    "# Create a model\n",
    "model = tc.object_detector.create(train_data, batch_size= 12, max_iterations= 20, verbose=False, all_iterations=True)\n",
    "#sys.stdout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to an SArray\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and save the results into a dictionary\n",
    "metrics = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use in Turi Create\n",
    "model.save('mymodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(output='dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sf = tc.SFrame('test.sframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docs.dict_trim_by_keys(turicreate.text_analytics.stopwords(), exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa = tc.SArray('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "with open('test.txt') as f, open('outfile.csv', 'w') as outfile:\n",
    "    for line in f:\n",
    "        line = re.sub('[|]', '', line)\n",
    "        line = re.sub('[+]', '', line)\n",
    "        line = re.sub('[-]','', line)\n",
    "        for word in line.split():\n",
    "            outfile.write(word + ',')\n",
    "        if not line.isspace():\n",
    "            outfile.write('\\n')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"outfile.csv\", usecols = ['Iteration', 'Loss', 'Elapsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df['Iteration']\n",
    "y1 = df['Loss']\n",
    "x1 = df['Elapsed']\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,y1)\n",
    "#plt.plot(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
